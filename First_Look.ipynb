{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "fdd6dea4-5c9d-4677-8de0-e89c850bf50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time \n",
    "import warnings\n",
    "from tqdm.notebook import trange, tqdm\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import glob\n",
    "import datetime\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "644a7f88",
   "metadata": {},
   "source": [
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "c91eb484-627e-40e0-98b0-bce04efd4798",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = {\n",
    "    0 : 'Пн',\n",
    "    1 : 'Вт',\n",
    "    2 : 'Ср',\n",
    "    3 : 'Чт',\n",
    "    4 : 'Пт',\n",
    "    5 : 'Сб',\n",
    "    6 : 'Вс'\n",
    "}\n",
    "weather_dict = {\n",
    "    \"akjar\":        \"Погода/Акъяр.xlsx\",\n",
    "    \"borovoe\":      \"Погода/Боровое.xlsx\",\n",
    "    \"bredy\":        \"Погода/Бреды.xlsx\",\n",
    "    \"krasnoepole\":  \"Погода/Красноеполе.xlsx\",\n",
    "    \"orsk\":         \"Погода/Орск.xlsx\",\n",
    "    \"pogoda\":       \"Погода/Погода p2.xlsx\",\n",
    "    \"chelyabinsk\":  \"Погода/Челябинск.xlsx\",\n",
    "    \"youjnostep\":   \"Погода/Южно-Степное.xlsx\",\n",
    "    \"magnitogorsk\": \"Погода/7Магнитогорскойптицефабрики(Первомайский).xlsx\",\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "b63af2fe-28ae-4c46-bc07-6636924e9941",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_target_set(target_name, how_to_shift, hours = 48):\n",
    "    Target_KS = pd.read_csv(target_name+\"P_in_out.csv\",sep = \";\")\n",
    "    Target_KS[\"DateTime\"] = pd.to_datetime(Target_KS[\"DateTime\"])   \n",
    "    Target_KS[\"dayofweek\"] = Target_KS[\"DateTime\"].dt.dayofweek\n",
    "    Target_KS[\"Pin\"] = Target_KS[\"Pin\"].str.replace(\",\",\".\").astype('float32')\n",
    "    Target_KS[\"Pout\"] = Target_KS[\"Pout\"].str.replace(\",\",\".\").astype('float32')\n",
    "    abs = pd.DataFrame()\n",
    "    abs[\"DateTime\"] = pd.date_range(Target_KS[\"DateTime\"].min(), periods=((Target_KS[\"DateTime\"].max() - Target_KS[\"DateTime\"].min()).seconds/3600 + (Target_KS[\"DateTime\"].max() - Target_KS[\"DateTime\"].min()).days*24 +1), freq=\"h\")\n",
    "    Target_KS = pd.merge(abs,Target_KS,how='left',on=\"DateTime\")\n",
    "    Target_KS = Target_KS.ffill() #Тут заполнение пропусков чтобы дискретность была час     \n",
    "    if how_to_shift == \"1\":\n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 0,'DateTime'] -= pd.DateOffset(hours=72)   \n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 1,'DateTime'] -= pd.DateOffset(hours=96) \n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 2,'DateTime'] -= pd.DateOffset(hours=48)\n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 3,'DateTime'] -= pd.DateOffset(hours=48)\n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 4,'DateTime'] -= pd.DateOffset(hours=48)\n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 5,'DateTime'] -= pd.DateOffset(hours=48)\n",
    "        Target_KS.loc[Target_KS['dayofweek'] == 6,'DateTime'] -= pd.DateOffset(hours=48)\n",
    "        Target_KS[\"dayofweek\"] = Target_KS[\"DateTime\"].dt.dayofweek\n",
    "        Target_KS[\"dayofweek\"] = Target_KS[\"dayofweek\"].replace(vocab, regex=True)\n",
    "        Target_KS.columns = [f'{c}_'+ target_name if c!=\"DateTime\" else c for c in Target_KS]\n",
    "        Target_KS = Target_KS.drop(Target_KS[(Target_KS[\"DateTime\"].dt.year < 2021)].index)\n",
    "        return Target_KS\n",
    "    elif how_to_shift == \"2\":\n",
    "        Target_KS['DateTime'] -= pd.DateOffset(hours=hours)\n",
    "        Target_KS[\"dayofweek\"] = Target_KS[\"DateTime\"].dt.dayofweek\n",
    "        Target_KS[\"dayofweek\"] = Target_KS[\"dayofweek\"].replace(vocab, regex=True)\n",
    "        Target_KS.rename(columns={\"Pin\": \"Pin_lag_\"+str(hours)+\"h\", \"Pout\": \"Pout_lag_\"+str(hours)+\"h\"}, inplace = True)\n",
    "        Target_KS.columns = [f'{c}_'+ target_name if c!=\"DateTime\" else c for c in Target_KS]\n",
    "        Target_KS = Target_KS.drop(Target_KS[(Target_KS[\"DateTime\"].dt.year < 2021)].index)\n",
    "        return Target_KS\n",
    "    else:        \n",
    "        Target_KS[\"dayofweek\"] = Target_KS[\"dayofweek\"].replace(vocab, regex=True)\n",
    "        Target_KS.columns = [f'{c}_'+ target_name if c!=\"DateTime\" else c for c in Target_KS]\n",
    "        return Target_KS\n",
    "   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "74be8cef-8892-4107-b58e-be110ee274f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_dataset(target_name, how_to_shift_target,hours = 48):\n",
    "    grs_list = glob.glob(\"ГРС/*\")\n",
    "    auto_plan_list = glob.glob(\"Автоплан/*\")\n",
    "    target_set = create_target_set(target_name, how_to_shift_target,hours)\n",
    "    schema_info = pd.read_csv(target_name+\".csv\",sep = \";\")\n",
    "    schema_info[\"DateTime\"] = pd.to_datetime(schema_info[\"DateTime\"])\n",
    "    target_set = pd.merge(target_set,schema_info,how='left',on=\"DateTime\")\n",
    "    for grs in tqdm(grs_list):\n",
    "        feature = pd.read_csv(grs, sep = \";\")\n",
    "        feature[\"DateTime\"] = pd.to_datetime(feature[\"DateTime\"])\n",
    "        for col in feature.columns:\n",
    "            if col == \"DateTime\":\n",
    "                continue \n",
    "            try:\n",
    "                feature[col] = feature[col].astype('float32')\n",
    "            except ValueError:\n",
    "                feature[col] = feature[col].str.replace(\",\",\".\").astype('float32')        \n",
    "        feature.columns = [f'{c}_'+ grs.split(\"\\\\\")[1][:-4] if c!=\"DateTime\" else c for c in feature]\n",
    "        target_set = pd.merge(target_set,feature,how='left',on=\"DateTime\")\n",
    "    for auto_list in tqdm(auto_plan_list):\n",
    "        feature = pd.read_csv(auto_list, sep = \";\")\n",
    "        if \"Date\" in feature.columns:\n",
    "            feature[\"Data\"] = feature[\"Date\"]\n",
    "            feature.drop(columns=[\"Date\"],inplace=True)\n",
    "        try:\n",
    "            feature[\"DateTime\"] = pd.to_datetime(feature[\"Data\"])\n",
    "        except KeyError:\n",
    "            continue\n",
    "        feature.drop(columns=[\"Data\"],inplace=True)\n",
    "        feature[\"DateTime\"] = pd.to_datetime(feature[\"DateTime\"])\n",
    "        for col in feature.columns:\n",
    "            if \"Login\" in feature.columns:\n",
    "                break\n",
    "            if col == \"DateTime\":\n",
    "                continue \n",
    "            try:\n",
    "                feature[col] = feature[col].astype('float32')\n",
    "            except ValueError:\n",
    "                feature[col] = feature[col].str.replace(\",\",\".\").astype('float32')   \n",
    "        feature.columns = [f'{c}_'+ auto_list.split(\"\\\\\")[1][:-4] if c!=\"DateTime\" else c for c in feature]\n",
    "        target_set = pd.merge(target_set,feature,how='left',on=\"DateTime\")\n",
    "    return target_set\n",
    "        \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "ff871a9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def correct_data_into_value(date):\n",
    "    if type(date) == type(datetime.datetime(2024, 2, 13, 0, 0)):\n",
    "        return str(f\"{date.day}.{date.month%12}\")\n",
    "    return date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "6ef30e4f-988d-45c7-815d-62e83935976d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_weather_dict_dataset():\n",
    "   weather_dfs = {}\n",
    "   for key, value in tqdm(weather_dict.items()):\n",
    "       active_df = pd.ExcelFile(value)\n",
    "       print(active_df.sheet_names)\n",
    "       for i in tqdm(active_df.sheet_names):\n",
    "           if len(active_df.sheet_names) < 2:\n",
    "               weather_dfs.update({key: {i: pd.read_excel(value,  sheet_name=i)}})\n",
    "           else:\n",
    "               for j in active_df.sheet_names:\n",
    "                   weather_dfs.update({f\"{key}_{j}\": {j: pd.read_excel(value,  sheet_name=j)}})\n",
    "   test_df = weather_dfs\n",
    "   for i in tqdm(weather_dfs.keys()):\n",
    "       for j in tqdm(weather_dfs[i].keys()):\n",
    "           print(f\"----{i}----\")\n",
    "           first_column = 1\n",
    "           for k in weather_dfs[i][j]:\n",
    "               if first_column == 1:\n",
    "                   first_column = 0\n",
    "                   continue\n",
    "               test_df[i][j][k] = weather_dfs[i][j][k].apply(lambda x: correct_data_into_value(x)).astype(\"float32\")\n",
    "   del weather_dfs\n",
    "   return test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "b922d10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def prepare_and_set_shift_and_lags(target_set, weather_set):\n",
    "    if target_set[\"PNA\"].dtype == \"object\":\n",
    "        target_set[\"PNA\"] = target_set[\"PNA\"].str.replace(\",\",\".\").astype('float32')\n",
    "    else:\n",
    "        target_set[\"PNA\"] = target_set[\"PNA\"].astype('float32')\n",
    "    target_set['Day'] = target_set[\"DateTime\"].dt.day\n",
    "    target_set['Month'] = target_set[\"DateTime\"].dt.month\n",
    "    target_set['Year'] = target_set[\"DateTime\"].dt.year\n",
    "    target_set['Hour'] = target_set[\"DateTime\"].dt.hour\n",
    "    target_set.columns = target_set.columns.str.replace(r\"\\n\", \"_\", regex=True)\n",
    "    for i in weather_set.keys():\n",
    "        for j in weather_set[i].keys():\n",
    "            buffer = weather_set[i][j].rename(lambda x: x+ (\"_\"+ i  )*int( x != \"Дата\"), axis='columns')\n",
    "            for columns in tqdm(buffer.columns):\n",
    "                if columns == \"Дата\":\n",
    "                    buffer['Day'] = buffer[\"Дата\"].dt.day\n",
    "                    buffer['Month'] = buffer[\"Дата\"].dt.month\n",
    "                    buffer['Year'] = buffer[\"Дата\"].dt.year\n",
    "                    continue\n",
    "                if buffer[columns].dtype == \"float64\":\n",
    "                    buffer[columns] = buffer[columns].astype(\"float32\")\n",
    "                if buffer[columns].dtype == \"float32\":\n",
    "                    buffer[columns + \"_rolling_3\"] = buffer[columns].rolling(3, min_periods = 1, center = False).sum()\n",
    "                # buffer[\"Date\"] = pd.to_datetime(buffer[\"Date\"], format=\"\"\n",
    "            buffer[columns + \"_lag_1\"] = buffer[columns].shift(1)\n",
    "            buffer[columns + \"_lag_2\"] = buffer[columns].shift(2)\n",
    "            buffer[columns + \"_lag_3\"] = buffer[columns].shift(3)\n",
    "            buffer[columns + \"_lag_7\"] = buffer[columns].shift(7)\n",
    "\n",
    "\n",
    "            buffer.drop(columns=[\"Дата\"], inplace=True)\n",
    "            \n",
    "            target_set = pd.merge(target_set, buffer, on=[\"Year\",\"Month\",\"Day\"])\n",
    "    del buffer\n",
    "    target_set.columns = target_set.columns.str.replace(r\"\\n\", \"_\", regex=True)\n",
    "    target_set[target_set.select_dtypes(include=['float64']).columns] = target_set[target_set.select_dtypes(include=['float64']).columns].astype(\"float32\")\n",
    "    target_set.ffill(inplace=True)\n",
    "    return target_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "63232ede-997d-4f8b-8950-04c38edd00aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_test_periodic_split(result, percentage=0.8,step = 0.1):\n",
    "    '''\n",
    "    Пока параметр step лучше не менять +- корректно работает в режимах  до 0.1 включительно\n",
    "    '''\n",
    "    full_dt_len  = result.DateTime.max() - result.DateTime.min()\n",
    "    train_set = pd.DataFrame(columns=result.columns)\n",
    "    test_set = pd.DataFrame(columns=result.columns)\n",
    "    min_date = result.DateTime.min()\n",
    "    start_date = full_dt_len/(10/step)\n",
    "    end_date = 2*full_dt_len/(10/step)\n",
    "    counter = step\n",
    "    while (end_date <= full_dt_len):\n",
    "        if counter <= percentage:\n",
    "            train_set = pd.concat([train_set,result.loc[(result.DateTime >= min_date+start_date) &(result.DateTime <= min_date+end_date)]],ignore_index=True)\n",
    "            counter+=step\n",
    "        elif counter>percentage:\n",
    "            test_set = pd.concat([test_set,result.loc[(result.DateTime >= min_date+start_date) &(result.DateTime <= min_date+end_date)]],ignore_index=True)\n",
    "            counter+=step\n",
    "        if counter >= 1:         \n",
    "            counter = 0.0\n",
    "        start_date+= full_dt_len/(10/step)\n",
    "        end_date+= full_dt_len/(10/step)\n",
    "    return train_set,test_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2227f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "Target_Name = [\"КС-15\",\"КС-16\",\"КС-17\",\"КС-19\"]\n",
    "Hours = [48, 72, 96]\n",
    "\n",
    "for i in Target_Name:\n",
    "    for j in Hours:\n",
    "        t_set = prepare_dataset(i, \"2\",hours= j)\n",
    "        weather_dfs = prepare_weather_dict_dataset()\n",
    "        result = prepare_and_set_shift_and_lags(t_set, weather_dfs)\n",
    "        train_set , test_set = train_test_periodic_split(result, percentage=0.8,step=0.01)\n",
    "        train_set.to_excel(\"train_set_\"+Target_Name +\"_h\"+str(Hours),index=None)\n",
    "        test_set.to_parquet(\"test_set_\"+Target_Name +\"_h\"+str(Hours),index=None)\n",
    "        test_set.to_excel(\"test_set_\"+Target_Name +\"_h\"+str(Hours),index=None)\n",
    "        test_set.to_parquet(\"test_set_\"+Target_Name +\"_h\"+str(Hours),index=None)\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
